{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 경제 분석 및 예측과 데이터 지능 실습2: Prophet, NeuralProphet\n",
    "\n",
    "본 실습은 시계열 예측을 위한 데이터 전처리와 대표적인 모듈 \"Prophet\", \"NeuralProphet\" 활용법을 다루고 있습니다.\n",
    "\n",
    "References:\n",
    "- [Modern Time Series Forecasting Techniques](https://medium.com/dataman-in-ai/mastering-time-series-forecasting-from-classical-foundations-to-cutting-edge-applications-0-1b0ac3da3188)\n",
    "- [Introduction to Statistical Learning](https://www.statlearning.com/)\n",
    "- [Prophet](https://facebook.github.io/prophet/)\n",
    "- [Neuralprophet](https://neuralprophet.com/)\n",
    "- [pmdarima](https://alkaline-ml.com/pmdarima/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from prophet import Prophet\n",
    "from prophet.plot import add_changepoints_to_plot\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "from sklearn import metrics\n",
    "import logging\n",
    "import warnings\n",
    "logging.getLogger(\"prophet\").setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prophet\n",
    "\n",
    "Meta에서 개발한 시계열 예측 라이브러리로, 비즈니스 환경에서 복잡한 패턴을 효과적으로 모델링하기 위해 고안되어 널리 활용되고 있습니다.\n",
    "\n",
    "Prophet은 Generalized Additive Model (GAM) 기반으로 작동하는데, 이는 각 구성요소를 가법적으로 결합하여 전체 시계열을 설명하는 모델입니다.\n",
    "\n",
    "Prophet의 모델의 표현:\n",
    "\n",
    "$Y(t)=T(t)+S(t)+H(t)+ϵ(t)$\n",
    "\n",
    "- T: 트렌드\n",
    "- S: 계절성\n",
    "- H: 휴일\n",
    "- $\\epsilon$ : 오차\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../datasets'\n",
    "data = pd.read_csv(path + '/daily-website-visitors.csv', thousands=',')\n",
    "\n",
    "data[\"Date\"] = pd.to_datetime(data[\"Date\"])\n",
    "data = data[['First.Time.Visits','Date']]\n",
    "data.columns = [\"y\", \"ds\"]\n",
    "data[\"y\"] = pd.to_numeric(data[\"y\"], errors='coerce')\n",
    "data = data[data[\"ds\"] >= pd.to_datetime('2017-01-01')]\n",
    "data = data.sort_values(by='ds')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data['ds'], data[\"y\"])\n",
    "plt.xlabel(\"date\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = int(data.shape[0] * 0.85)\n",
    "train = data.iloc[:train_len,:]\n",
    "test = data.iloc[train_len:,:]\n",
    "[train_len, len(test)]\n",
    "# [1127, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Prophet()\n",
    "m.add_country_holidays(country_name='US')\n",
    "m.fit(train)\n",
    "\n",
    "future= m.make_future_dataframe(periods=len(test), freq='d')\n",
    "future.tail()\n",
    "\n",
    "forecast=m.predict(future)\n",
    "forecast.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = m.plot(forecast)\n",
    "a = add_changepoints_to_plot(fig.gca(), m, forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape = metrics.mean_absolute_percentage_error(list(test['y']), list(forecast.loc[train_len:,'yhat']))\n",
    "mae = metrics.mean_absolute_error(list(test['y']), list(forecast.loc[train_len:,'yhat']))\n",
    "mse = metrics.mean_squared_error(list(test['y']), list(forecast.loc[train_len:,'yhat']))\n",
    "\n",
    "print(f' mape: {mape}')\n",
    "print(f'mae : {mae}')\n",
    "print(f'mse : {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv = cross_validation(m, initial='730 days', period='180 days', horizon = '365 days')\n",
    "df_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_perf = performance_metrics(df_cv)\n",
    "m_perf.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼 패러미터 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyper-parameter grids\n",
    "changepoint_prior_scale = [0.001, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "seasonality_prior_scale = [1, 5, 10, 15]  # default 10\n",
    "seasonality_model = ['additive', 'multiplicative']\n",
    "\n",
    "results = []\n",
    "iteration = 1\n",
    "\n",
    "# Loop over all combinations of hyper-parameters\n",
    "for sm in seasonality_model:\n",
    "    for s in seasonality_prior_scale:\n",
    "        for cp in changepoint_prior_scale:\n",
    "            m = Prophet(\n",
    "                seasonality_mode=sm,\n",
    "                seasonality_prior_scale=s,\n",
    "                changepoint_prior_scale=cp,\n",
    "            )\n",
    "            m.add_country_holidays(country_name='US')\n",
    "            model = m.fit(train)\n",
    "            future = model.make_future_dataframe(periods=len(test), freq='D')\n",
    "            forecast = model.predict(future)\n",
    "            # Compute evaluation metrics on the test set;\n",
    "            # assume 'train_len' holds the length of the training set\n",
    "            mape = metrics.mean_absolute_percentage_error(\n",
    "                list(test['y']),\n",
    "                list(forecast.loc[train_len:, 'yhat'])\n",
    "            )\n",
    "            mae = metrics.mean_absolute_error(\n",
    "                list(test['y']),\n",
    "                list(forecast.loc[train_len:, 'yhat'])\n",
    "            )\n",
    "            mse = metrics.mean_squared_error(\n",
    "                list(test['y']),\n",
    "                list(forecast.loc[train_len:, 'yhat'])\n",
    "            )\n",
    "            print(f'Iteration {iteration} -- mape: {mape}')\n",
    "            results.append([iteration, sm, s, cp, mape, mae, mse])\n",
    "            iteration += 1\n",
    "\n",
    "# Convert results list to a DataFrame\n",
    "results = pd.DataFrame(\n",
    "    results,\n",
    "    columns=['iteration', 'seasonality_mode', 'seasonality_prior_scale',\n",
    "             'changepoint_prior_scale', 'mape', 'mae', 'mse']\n",
    ")\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model (first record in results) for diagnostics\n",
    "sm_best = results.loc[0, 'seasonality_mode']\n",
    "sp_best = results.loc[0, 'seasonality_prior_scale']\n",
    "cp_best = results.loc[0, 'changepoint_prior_scale']\n",
    "\n",
    "m1 = Prophet(\n",
    "    seasonality_mode=sm_best,\n",
    "    seasonality_prior_scale=sp_best,\n",
    "    changepoint_range=cp_best,\n",
    ")\n",
    "m1.add_country_holidays(country_name='US')\n",
    "m1.fit(train)\n",
    "future = m1.make_future_dataframe(periods=len(test), freq='D')\n",
    "forecast = m1.predict(future)\n",
    "\n",
    "m1_cv = cross_validation(\n",
    "    m1,\n",
    "    initial='100 days',\n",
    "    period='180 days',\n",
    "    horizon='365 days'\n",
    ")\n",
    "m1_perf = performance_metrics(m1_cv)\n",
    "print(m1_perf.head())\n",
    "\n",
    "fig = m1.plot_components(forecast)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuralprophet\n",
    "\n",
    "NeuralProphet는 Prophet 모델의 확장판으로, 딥러닝 모듈을 도입하여 보다 복잡한 시계열 패턴을 모델링할 수 있습니다.\n",
    "\n",
    "모델 구성:\n",
    "$$\n",
    "Y(t) = T(t) + S(t) + E(t) + A(t) + L(t) + F(t)\n",
    "$$\n",
    "\n",
    "- $T(t)$: 시계열의 추세(Trend)\n",
    "- $S(t)$: 계절성(Seasonality)\n",
    "- $E(t)$: 이벤트(Event) 효과\n",
    "- $A(t)$: 자동회귀(Autoregressive) 성분\n",
    "- $L(t)$: 레벨(Level) 변화\n",
    "- $F(t)$: 잔차(Residual) 또는 기타 효과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(path + \"/bike_sharing_daily.csv\")\n",
    "data[\"ds\"] = pd.to_datetime(data[\"dteday\"])\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[[\"ds\", \"cnt\"]]\n",
    "df.columns = [\"ds\", \"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df['ds'], df[\"y\"])\n",
    "plt.xlabel(\"date\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralprophet import NeuralProphet, set_log_level\n",
    "set_log_level(\"ERROR\")\n",
    "\n",
    "m = NeuralProphet()\n",
    "metrics = m.fit(df)\n",
    "\n",
    "df_future = m.make_future_dataframe(df, n_historic_predictions=True, # include entire history\n",
    "                                     periods=365)\n",
    "\n",
    "forecast = m.predict(df_future)\n",
    "\n",
    "m.plot(forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only Trend without changepoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trend without change points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = NeuralProphet(\n",
    "    n_changepoints=0,\n",
    "    yearly_seasonality=False,\n",
    "    weekly_seasonality=False,\n",
    "    daily_seasonality=False\n",
    ")\n",
    "\n",
    "df_future = m.make_future_dataframe(df, periods=365, n_historic_predictions=True)\n",
    "m.set_plotting_backend(\"matplotlib\")\n",
    "df_train, df_test = m.split_df(df, valid_p=0.2)\n",
    "metrics = m.fit(df_train, validation_df=df_test, progress=\"bar\")\n",
    "forecast = m.predict(df_future)\n",
    "m.plot(forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trend without changepoint + Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = NeuralProphet(\n",
    "    n_changepoints=0,\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    daily_seasonality=False\n",
    ")\n",
    "\n",
    "df_future = m.make_future_dataframe(df, periods=365, n_historic_predictions=True)\n",
    "m.set_plotting_backend(\"matplotlib\")\n",
    "df_train, df_test = m.split_df(df, valid_p=0.2)\n",
    "metrics = m.fit(df_train, validation_df=df_test, progress=\"bar\")\n",
    "forecast = m.predict(df_future)\n",
    "m.plot(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot_parameters(components=[\"trend\", \"seasonality\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trend **with** changepoint + Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = NeuralProphet(\n",
    "    n_changepoints=10,\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    daily_seasonality=False\n",
    ")\n",
    "\n",
    "df_future = m.make_future_dataframe(df, periods=365, n_historic_predictions=True)\n",
    "m.set_plotting_backend(\"matplotlib\")\n",
    "df_train, df_test = m.split_df(df, valid_p=0.2)\n",
    "metrics = m.fit(df_train, validation_df=df_test, progress=\"bar\")\n",
    "forecast = m.predict(df_future)\n",
    "m.plot(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot_parameters(components=[\"trend\", \"seasonality\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trend **with** changepoint + Seasonality + Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = NeuralProphet(\n",
    "    n_changepoints=10,\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    daily_seasonality=False\n",
    ")\n",
    "\n",
    "m = m.add_country_holidays(\"US\")\n",
    "\n",
    "df_future = m.make_future_dataframe(df, periods=365, n_historic_predictions=True)\n",
    "m.set_plotting_backend(\"matplotlib\")\n",
    "df_train, df_test = m.split_df(df, valid_p=0.2)\n",
    "metrics = m.fit(df_train, validation_df=df_test, progress=\"bar\")\n",
    "forecast = m.predict(df_future)\n",
    "m.plot(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot_parameters(components=[\"trend\", \"seasonality\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trend **with** changepoint + Seasonality + Events + AR-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = NeuralProphet(\n",
    "    n_changepoints=10,\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    daily_seasonality=False,\n",
    "    n_lags = 10\n",
    ")\n",
    "\n",
    "m = m.add_country_holidays(\"US\")\n",
    "\n",
    "df_future = m.make_future_dataframe(df, periods=365, n_historic_predictions=True)\n",
    "m.set_plotting_backend(\"matplotlib\")\n",
    "df_train, df_test = m.split_df(df, valid_p=0.2)\n",
    "metrics = m.fit(df_train, validation_df=df_test, progress=\"bar\")\n",
    "forecast = m.predict(df_future)\n",
    "m.plot(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot_parameters(components=[\"trend\", \"seasonality\", \"autoregression\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trend **with** changepoint + Seasonality + Events + AR-net + lagged regressors + future known regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = data[[\"ds\", \"cnt\", \"temp\", \"casual\"]]\n",
    "df2.columns = [\"ds\", \"y\", \"temperature\", \"casual\"]\n",
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = df2.plot(x = \"ds\", y = \"y\", figsize = (10,6))\n",
    "df2.plot(\"ds\", \"temperature\", secondary_y=True, ax=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = df2.plot(x = \"ds\", y = \"y\", figsize = (10,6))\n",
    "df2.plot(\"ds\", \"casual\", secondary_y=True, ax=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = NeuralProphet(\n",
    "    n_changepoints=10,\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    daily_seasonality=False,\n",
    "    n_lags = 10,\n",
    "    n_forecasts=50\n",
    ")\n",
    "\n",
    "m = m.add_country_holidays(\"US\")\n",
    "m = m.add_lagged_regressor(\"casual\", n_lags=2)\n",
    "m = m.add_future_regressor(\"temperature\")\n",
    "\n",
    "m.set_plotting_backend(\"matplotlib\")\n",
    "df2_train, df2_test = m.split_df(df2, valid_p=0.2)\n",
    "metrics = m.fit(df2_train, validation_df=df2_test, progress=\"bar\")\n",
    "metrics.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_dates = pd.date_range(start=df2['ds'].max() + pd.Timedelta(days=1), periods=50, freq='D')\n",
    "future_regressors = pd.DataFrame({'ds': future_dates})\n",
    "future_regressors['temperature'] = df2['temperature'].iloc[-1]\n",
    "\n",
    "future = m.make_future_dataframe(\n",
    "    df=df2, \n",
    "    periods=50, \n",
    "    n_historic_predictions=True, \n",
    "    regressors_df=future_regressors\n",
    ")\n",
    "\n",
    "forecast = m.predict(future)\n",
    "\n",
    "fig_forecast = m.plot(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot_parameters(components=[\"trend\", \"seasonality\", \"autoregression\",\"lagged_regressors\", \"future_regressors\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with pmdarima\n",
    "\n",
    "neuralprophet으로 추세, 계절성을 잡고 ARIMA를 통해 나머지를 적합하는 접근 방법도 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from neuralprophet import NeuralProphet\n",
    "import pmdarima as pm\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Baseline NP Forecast\n",
    "# -------------------------------\n",
    "# Initialize and configure the NeuralProphet model\n",
    "m = NeuralProphet(\n",
    "    n_changepoints=10,\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    daily_seasonality=False,\n",
    "    n_forecasts=1\n",
    ")\n",
    "m = m.add_country_holidays(\"US\")\n",
    "m.set_plotting_backend(\"matplotlib\")\n",
    "\n",
    "# Split the data into training and test sets\n",
    "df_train, df_test = m.split_df(df, valid_p=0.2)\n",
    "\n",
    "# Fit the model on training data\n",
    "metrics = m.fit(df_train, validation_df=df_test, progress=\"bar\")\n",
    "print(\"Baseline NP Model Metrics:\")\n",
    "print(metrics.tail())\n",
    "\n",
    "# Forecast NP for the test period\n",
    "df_future_test = m.make_future_dataframe(df_train, periods=len(df_test), n_historic_predictions=False)\n",
    "forecast_np = m.predict(df_future_test)\n",
    "\n",
    "# Rename the forecast column for clarity (baseline NP forecast)\n",
    "df_np = forecast_np[[\"ds\", \"yhat1\"]].copy()\n",
    "df_np.rename(columns={\"yhat1\": \"y_np\"}, inplace=True)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Hybrid NP + ARIMA Forecast\n",
    "# -------------------------------\n",
    "# Compute NP predictions on the training set and calculate residuals\n",
    "df_train_pred = m.predict(df_train)\n",
    "residuals = df_train[\"y\"].values - df_train_pred[\"yhat1\"].values\n",
    "\n",
    "# Fit an auto-ARIMA model to the residuals (non-seasonal)\n",
    "model_arima = pm.auto_arima(residuals, seasonal=False)\n",
    "\n",
    "# Forecast residuals for the test period\n",
    "residuals_forecast = model_arima.predict(n_periods=len(df_test))\n",
    "\n",
    "# Create a hybrid forecast by adding ARIMA's residual forecast to NP's forecast\n",
    "df_hybrid = df_np.copy()\n",
    "df_hybrid[\"y_arima\"] = df_hybrid[\"y_np\"] + residuals_forecast\n",
    "\n",
    "# -------------------------------\n",
    "# 3. NP with AR-net (n_lags=10)\n",
    "# -------------------------------\n",
    "# Initialize NP with autoregression (using 10 lagged terms)\n",
    "m_ar = NeuralProphet(\n",
    "    n_changepoints=10,\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    daily_seasonality=False,\n",
    "    n_lags=10,\n",
    "    n_forecasts=1\n",
    ")\n",
    "m_ar = m_ar.add_country_holidays(\"US\")\n",
    "m_ar.set_plotting_backend(\"matplotlib\")\n",
    "\n",
    "# Split the data and fit the model\n",
    "df_train_ar, df_test_ar = m_ar.split_df(df, valid_p=0.2)\n",
    "metrics_ar = m_ar.fit(df_train_ar, validation_df=df_test_ar, progress=\"bar\")\n",
    "print(\"NP with AR-net Model Metrics:\")\n",
    "print(metrics_ar.tail())\n",
    "\n",
    "# Predict using NP with AR-net on the test set\n",
    "forecast_arnet = m_ar.predict(df_test_ar)\n",
    "# Ensure that the forecast dates are aligned with the test set dates\n",
    "df_test_ar_sorted = df_test_ar.sort_values(\"ds\").reset_index(drop=True)\n",
    "valid_length = len(forecast_arnet)\n",
    "df_arnet = pd.DataFrame({\n",
    "    \"ds\": pd.to_datetime(df_test_ar_sorted[\"ds\"].values[-valid_length:]),\n",
    "    \"y_arnet\": forecast_arnet[\"yhat1\"].values\n",
    "})\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Merge all forecasts with actual test values\n",
    "# -------------------------------\n",
    "# Prepare actual test values\n",
    "df_actual = df_test[[\"ds\", \"y\"]].copy()\n",
    "df_actual.rename(columns={\"y\": \"y_actual\"}, inplace=True)\n",
    "df_actual[\"ds\"] = pd.to_datetime(df_actual[\"ds\"])\n",
    "\n",
    "# Merge forecasts from baseline NP, the hybrid NP+ARIMA, and NP with AR-net\n",
    "df_merged = pd.merge(df_np, df_actual, on=\"ds\", how=\"outer\")\n",
    "df_merged = pd.merge(df_merged, df_hybrid[[\"ds\", \"y_arima\"]], on=\"ds\", how=\"outer\")\n",
    "df_merged = pd.merge(df_merged, df_arnet, on=\"ds\", how=\"outer\")\n",
    "df_merged.sort_values(\"ds\", inplace=True, ignore_index=True)\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Compute error metrics for each forecast\n",
    "# -------------------------------\n",
    "def compute_metrics(df, y_true_col, y_pred_col):\n",
    "    # Compare rows where both actual and predicted values are available\n",
    "    df_valid = df.dropna(subset=[y_true_col, y_pred_col])\n",
    "    y_true = df_valid[y_true_col].values\n",
    "    y_pred = df_valid[y_pred_col].values\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    return mae, rmse, mape\n",
    "\n",
    "mae_np, rmse_np, mape_np = compute_metrics(df_merged, \"y_actual\", \"y_np\")\n",
    "mae_hybrid, rmse_hybrid, mape_hybrid = compute_metrics(df_merged, \"y_actual\", \"y_arima\")\n",
    "mae_arnet, rmse_arnet, mape_arnet = compute_metrics(df_merged, \"y_actual\", \"y_arnet\")\n",
    "\n",
    "print(\"\\nError Metrics on Test Data:\")\n",
    "print(\"Baseline NP Forecast:\")\n",
    "print(f\"  MAE: {mae_np:.2f}, RMSE: {rmse_np:.2f}, MAPE: {mape_np:.2%}\")\n",
    "print(\"Hybrid Forecast (NP + ARIMA):\")\n",
    "print(f\"  MAE: {mae_hybrid:.2f}, RMSE: {rmse_hybrid:.2f}, MAPE: {mape_hybrid:.2%}\")\n",
    "print(\"NP with AR-net (n_lags=10):\")\n",
    "print(f\"  MAE: {mae_arnet:.2f}, RMSE: {rmse_arnet:.2f}, MAPE: {mape_arnet:.2%}\")\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    \"Forecasting Method\": [\"Baseline NP\", \"Hybrid (NP+ARIMA)\", \"NP with AR-net\"],\n",
    "    \"MAE\": [mae_np, mae_hybrid, mae_arnet],\n",
    "    \"RMSE\": [rmse_np, rmse_hybrid, rmse_arnet],\n",
    "    \"MAPE\": [mape_np, mape_hybrid, mape_arnet]\n",
    "})\n",
    "print(\"\\nComparison of Error Metrics:\")\n",
    "print(metrics_df)\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Plot the Forecasts\n",
    "# -------------------------------\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_merged[\"ds\"], df_merged[\"y_actual\"], label=\"Actual Test Data\", color=\"black\")\n",
    "plt.plot(df_merged[\"ds\"], df_merged[\"y_np\"], label=\"NP Forecast\", color=\"blue\")\n",
    "plt.plot(df_merged[\"ds\"], df_merged[\"y_arima\"], label=\"Hybrid (NP+ARIMA)\", color=\"red\")\n",
    "plt.plot(df_merged[\"ds\"], df_merged[\"y_arnet\"], label=\"NP with AR-net (n_lags=10)\", color=\"green\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Test Period Forecast Comparison\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_merged[\"ds\"], df_merged[\"y_actual\"], label=\"Actual Test Data\", color=\"black\")\n",
    "plt.plot(df_merged[\"ds\"], df_merged[\"y_np\"], label=\"NP Forecast\", color=\"blue\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Test Period Forecast Comparison\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecasting_lecture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
